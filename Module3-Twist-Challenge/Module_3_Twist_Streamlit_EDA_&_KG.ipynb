{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Overview"
      ],
      "metadata": {
        "id": "fnMKtXkjXsRh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This Notebook contains code for designing 2 applications:\n",
        "\n",
        "1. An EDA web application for ACLED dataset.\n",
        "2. A knowledge graph web application.\n",
        "\n",
        "Both web applications were developed by streamlit but hosted localy due to time constraints.\n",
        "\n",
        "The sections in this notebook are:\n",
        "\n",
        "1. Importing libraries and dependencies.\n",
        "2. Code for developing EDA application.\n",
        "3. Code for Knowledge Graph application.\n",
        "\n",
        "**NB**: Reasoning behind creating 2 applications rather than 1, was to improve latency and time taken to reload the interactive independent dashboard sections.\n",
        "An accompanying video for the web app demos can be found on the Google drive [here](https://drive.google.com/drive/folders/1Wb351y-EaWjTnjRCOojVtcNHE4CiUY2e)."
      ],
      "metadata": {
        "id": "-Vma42QDXw2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1. Install Libraries and Dependencies"
      ],
      "metadata": {
        "id": "fMbo_feTXj6y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "SuUfjdkk_Npw"
      },
      "outputs": [],
      "source": [
        "#!pip3 install geopandas\n",
        "#!pip install streamlit\n",
        "#!pip install pyvis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9X9IVM4RVqdR"
      },
      "outputs": [],
      "source": [
        "#!pip install boto3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "kmFBtXL3a1Co"
      },
      "outputs": [],
      "source": [
        "#!pip3 install networkx==2.3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##1.2 Mounting Drive"
      ],
      "metadata": {
        "id": "MXopKSt6ZV2C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-P6vHgyAxMS",
        "outputId": "1331684a-3b73-49b8-a110-d735ca2ff4aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "## Mount drive\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "7epLGXSiA1jh"
      },
      "outputs": [],
      "source": [
        "os.chdir('/content/drive/MyDrive/Module3-Twist-Challenge')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2.1 Exploratory Analysis Application Development"
      ],
      "metadata": {
        "id": "kniQsd9RbVeP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code generates the EDA application on the ACLED dataset."
      ],
      "metadata": {
        "id": "hA3B56miblDr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "\n",
        "## Import Libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import datetime as dt\n",
        "import geopandas\n",
        "import plotly.express as px \n",
        "import seaborn as sns\n",
        "import os\n",
        "import streamlit as st\n",
        "from streamlit import components\n",
        "from pyvis.network import Network\n",
        "sns.set_theme()\n",
        "\n",
        "import re\n",
        "import bs4\n",
        "import requests\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "from spacy.matcher import Matcher \n",
        "from spacy.tokens import Span \n",
        "\n",
        "import networkx as nx\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import boto3\n",
        "from io import StringIO\n",
        "\n",
        "## Switch off warnings\n",
        "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
        "\n",
        "## Load Data\n",
        "@st.cache\n",
        "def load_data():\n",
        "  \"\"\"\n",
        "  Import data from S3 bucket\n",
        "  \"\"\"\n",
        "  ## Read in data\n",
        "  aws_access_key_id = 'XXXXXXXXXXXXXXXXXXX'\n",
        "  aws_secret_access_key = 'XXXXXXXXXXXXXXXXXXX'\n",
        "\n",
        "  client = boto3.client('s3', aws_access_key_id=aws_access_key_id,\n",
        "          aws_secret_access_key=aws_secret_access_key)\n",
        "\n",
        "  bucket_name = 'dsi-acled-data'\n",
        "\n",
        "  object_key = '2019-04-09-2022-04-14.csv'\n",
        "  csv_obj = client.get_object(Bucket=bucket_name, Key=object_key)\n",
        "  body = csv_obj['Body']\n",
        "  csv_string = body.read().decode('utf-8')\n",
        "\n",
        "  acled_data = pd.read_csv(StringIO(csv_string))\n",
        "\n",
        "  ## Date manipulation\n",
        "  acled_data['date'] = pd.to_datetime(acled_data['event_date'])\n",
        "  acled_data['year_mon'] = acled_data['date'].dt.to_period('M')\n",
        "  acled_data['year_mon2'] = acled_data['year_mon'].astype(str)\n",
        "\n",
        "  ## Replace DRC name\n",
        "  acled_data['country'] = acled_data['country'].str.replace('Democratic Republic of Congo','DRC')\n",
        "\n",
        "  return acled_data\n",
        "\n",
        "## Read data in memory\n",
        "acled_data = load_data()\n",
        "\n",
        "#Add title and subtitle to the main interface of the app\n",
        "st.title('Armed Conflict Location & Event Data Analysis')\n",
        "\n",
        "min_date = acled_data['date'].min()\n",
        "max_date = acled_data['date'].max()\n",
        "\n",
        "start_date = st.date_input('Start Date', value=min_date, min_value=min_date, max_value=max_date)\n",
        "end_date = st.date_input('End Date', value=max_date, min_value=min_date, max_value=max_date)\n",
        "\n",
        "start_date = pd.to_datetime(start_date)\n",
        "end_date = pd.to_datetime(end_date)\n",
        "\n",
        "filtered_acled_data = acled_data[((acled_data['date'] >= start_date) & (acled_data['date'] < end_date))]\n",
        "\n",
        "st.subheader(\"Africa Analytics\")\n",
        "\n",
        "## Filter for Africa\n",
        "africa = filtered_acled_data[filtered_acled_data['region'].str.contains(\"Africa\")]\n",
        "\n",
        "## Conflicts by country\n",
        "africa_conflicts = africa.groupby('country')['event_id_no_cnty'].count().reset_index(name='events_count').sort_values(['events_count'],ascending=False)\n",
        "\n",
        "## Fatalities by country\n",
        "africa_fatalities = africa.groupby('country')['fatalities'].sum().reset_index(name='fatalities_counts').sort_values(['fatalities_counts'],ascending=False)\n",
        "\n",
        "## Event Types\n",
        "africa_event_types = africa.groupby('event_type')['event_type'].count().reset_index(name='event_type_count').sort_values(['event_type_count'],ascending=False)\n",
        "\n",
        "## Fatalities by month\n",
        "fatalities_by_month = africa.groupby('year_mon')['fatalities'].sum().reset_index(name='fatalities_by_month')\n",
        "fatalities_by_month['year_mon2'] = fatalities_by_month['year_mon'].astype(str)\n",
        "\n",
        "## Events distribution by country\n",
        "africa_analytics_bars = st.container()\n",
        "with africa_analytics_bars:\n",
        "  bar_chart1, bar_chart2 = st.columns(2)\n",
        "\n",
        "  top_ten_events = africa_conflicts[:10]\n",
        "  fig1 = px.bar(top_ten_events, x='events_count', y='country',title=\"Conflict Events by Country\",orientation='h')\n",
        "  fig1.update_layout(yaxis={'categoryorder':'total ascending'}) \n",
        "\n",
        "  top_ten_fatalities = africa_fatalities[:10]\n",
        "  fig2 = px.bar(top_ten_fatalities, x='fatalities_counts', y='country',title=\"Fatalities by Country\",orientation='h')\n",
        "  fig2.update_layout(yaxis={'categoryorder':'total ascending'}) \n",
        "  \n",
        "  bar_chart1.plotly_chart(fig1)\n",
        "  bar_chart2.plotly_chart(fig2)\n",
        "\n",
        "\n",
        "## Distribution of Event Types\n",
        "africa_analytics_conflict_types = st.container()\n",
        "with africa_analytics_conflict_types:\n",
        "  bar_chart3,bar_chart4 = st.columns(2)\n",
        "\n",
        "  fig3 = px.bar(africa_event_types, x='event_type_count', y='event_type',title=\"Distribution of Event Types\",orientation='h')\n",
        "  fig3.update_layout(yaxis={'categoryorder':'total ascending'}) \n",
        "\n",
        "  fig4 = px.line(fatalities_by_month, x=\"year_mon2\", y=\"fatalities_by_month\", title='Fatalities by Month')\n",
        "\n",
        "  \n",
        "  \n",
        "  bar_chart3.plotly_chart(fig3)\n",
        "  bar_chart4.plotly_chart(fig4)\n",
        "\n",
        "## Geo-Map for event distribution\n",
        "continental_analysis_events = st.container()\n",
        "with continental_analysis_events:\n",
        "\n",
        "  Cumulative_cases_plot = px.choropleth(africa_conflicts,\n",
        "                      locations=\"country\", #Spatial coordinates and corrseponds to a column in dataframe\n",
        "                      color=\"events_count\", #Corresponding data in the dataframe\n",
        "                      locationmode = 'country names', #location mode == One of ‘ISO-3’, ‘USA-states’, or ‘country names’ \n",
        "                      #locationmode == should match the type of data entries in \"locations\"\n",
        "                      scope=\"africa\", #limits the scope of the map to Africa\n",
        "                      title =\"Conflict Events Distribution in Africa\",\n",
        "                      hover_name=\"country\",\n",
        "                      color_continuous_scale = \"deep\",\n",
        "                    )\n",
        "  Cumulative_cases_plot.update_traces(marker_line_color=\"black\") # line markers between states\n",
        "  st.plotly_chart(Cumulative_cases_plot)\n",
        "\n",
        "\n",
        "## Fatality distribution Geo-Map\n",
        "continental_analysis_fatalities = st.container()\n",
        "with continental_analysis_fatalities:\n",
        "  Cumulative_fatalities_plot = px.choropleth(africa_fatalities,\n",
        "                      locations=\"country\", #Spatial coordinates and corrseponds to a column in dataframe\n",
        "                      color=\"fatalities_counts\", #Corresponding data in the dataframe\n",
        "                      locationmode = 'country names', #location mode == One of ‘ISO-3’, ‘USA-states’, or ‘country names’ \n",
        "                      #locationmode == should match the type of data entries in \"locations\"\n",
        "                      scope=\"africa\", #limits the scope of the map to Africa\n",
        "                      title =\"Conflict Fatality Distribution in Africa\",\n",
        "                      hover_name=\"country\",\n",
        "                      color_continuous_scale = \"reds\",\n",
        "                    )\n",
        "  Cumulative_fatalities_plot.update_traces(marker_line_color=\"black\") # line markers between states\n",
        "  st.plotly_chart(Cumulative_fatalities_plot)"
      ],
      "metadata": {
        "id": "MmoySo4xbwOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2 Run EDA Streamlit Application"
      ],
      "metadata": {
        "id": "5MNtnRwZdQYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The below code snipet generates a link for the EDA web app."
      ],
      "metadata": {
        "id": "7iPsBoBfdWe9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run app.py & npx localtunnel --port 8501"
      ],
      "metadata": {
        "id": "Az3sW0gJdfnG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.1  Knowledge Graph Application Development"
      ],
      "metadata": {
        "id": "tr-3rRFNZdBC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code generates the streamlit application for the Knowledge graph."
      ],
      "metadata": {
        "id": "QAdpABIEa2hu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TL6lz9bluU8X",
        "outputId": "f5093cd4-d639-4542-f64a-85bb9d7b9ab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting app2.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app2.py\n",
        "## Load libraries\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import datetime as dt\n",
        "import geopandas\n",
        "import plotly.express as px \n",
        "import seaborn as sns\n",
        "import os\n",
        "import streamlit as st\n",
        "from streamlit import components\n",
        "sns.set_theme()\n",
        "\n",
        "import re\n",
        "import bs4\n",
        "import requests\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "from spacy.matcher import Matcher \n",
        "from spacy.tokens import Span \n",
        "\n",
        "import networkx as nx\n",
        "from pyvis.network import Network\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm\n",
        "import boto3\n",
        "from io import StringIO\n",
        "\n",
        "## Switch off warnings\n",
        "st.set_option('deprecation.showPyplotGlobalUse', False)\n",
        "\n",
        "## Page title\n",
        "st.title('Armed Conflict Location & Event Network Analysis')\n",
        "\n",
        "## Load data\n",
        "@st.cache\n",
        "def load_data():\n",
        "\n",
        "  \"\"\"\n",
        "  Loads  data from s3 bucket\n",
        "  \"\"\"\n",
        "  \n",
        "  ## Read in data from s3 bucket\n",
        "\n",
        "  ## AWS keys\n",
        "  aws_access_key_id = 'XXXXXXXXXXXXXXXXXXX'\n",
        "  aws_secret_access_key = 'XXXXXXXXXXXXXXX'\n",
        "\n",
        "  client = boto3.client('s3', aws_access_key_id=aws_access_key_id,\n",
        "          aws_secret_access_key=aws_secret_access_key)\n",
        "\n",
        "  bucket_name = 'dsi-acled-data'\n",
        "\n",
        "  object_key = '2019-04-09-2022-04-14.csv'\n",
        "  csv_obj = client.get_object(Bucket=bucket_name, Key=object_key)\n",
        "  body = csv_obj['Body']\n",
        "  csv_string = body.read().decode('utf-8')\n",
        "\n",
        "  acled_data = pd.read_csv(StringIO(csv_string))\n",
        "\n",
        "  ## Date manipulations\n",
        "  acled_data['date'] = pd.to_datetime(acled_data['event_date'])\n",
        "  acled_data['year_mon'] = acled_data['date'].dt.to_period('M')\n",
        "  acled_data['year_mon2'] = acled_data['year_mon'].astype(str)\n",
        "\n",
        "  ## Replace DRC name\n",
        "  acled_data['country'] = acled_data['country'].str.replace('Democratic Republic of Congo','DRC')\n",
        "\n",
        "  return acled_data\n",
        "\n",
        "acled_data = load_data()\n",
        "\n",
        "## Filter for Africa\n",
        "africa = acled_data[acled_data['region'].str.contains(\"Africa\")]\n",
        "\n",
        "## Filter for country\n",
        "africa_select = africa[['event_date','year','event_type','actor1','actor2','region','country','notes','fatalities']]\n",
        "\n",
        "st.write('Select country of interest for network analysis using knowledge graph')\n",
        "\n",
        "selected_country = st.selectbox(\n",
        "    'Select Country for Network Analysis',\n",
        "    africa['country'].unique())\n",
        "\n",
        "country_data = africa_select[africa_select['country']==selected_country]\n",
        "\n",
        "#Add title and subtitle to the main interface of the app\n",
        "\n",
        "\n",
        "st.subheader(\"Country Network Analysis\")\n",
        "st.write('To generate entities and relations from the ACLED data click the button below.')\n",
        "\n",
        "if st.button('Generate Entities and Relations'):\n",
        "  with st.spinner(\"Generating Entities and Relations\"):\n",
        "    ## Entities Extraction\n",
        "\n",
        "    def get_entities(sent):\n",
        "\n",
        "      ## chunk 1\n",
        "      ent1 = \"\"\n",
        "      ent2 = \"\"\n",
        "\n",
        "      prv_tok_dep = \"\"    # dependency tag of previous token in the sentence\n",
        "      prv_tok_text = \"\"   # previous token in the sentence\n",
        "\n",
        "      prefix = \"\"\n",
        "      modifier = \"\"\n",
        "\n",
        "      #############################################################\n",
        "      \n",
        "      for tok in nlp(sent):\n",
        "        ## chunk 2\n",
        "        # if token is a punctuation mark then move on to the next token\n",
        "        if tok.dep_ != \"punct\":\n",
        "          # check: token is a compound word or not\n",
        "          if tok.dep_ == \"compound\":\n",
        "            prefix = tok.text\n",
        "            # if the previous word was also a 'compound' then add the current word to it\n",
        "            if prv_tok_dep == \"compound\":\n",
        "              prefix = prv_tok_text + \" \"+ tok.text\n",
        "          \n",
        "          # check: token is a modifier or not\n",
        "          if tok.dep_.endswith(\"mod\") == True:\n",
        "            modifier = tok.text\n",
        "            # if the previous word was also a 'compound' then add the current word to it\n",
        "            if prv_tok_dep == \"compound\":\n",
        "              modifier = prv_tok_text + \" \"+ tok.text\n",
        "          \n",
        "          ## chunk 3\n",
        "          if tok.dep_.find(\"subj\") == True:\n",
        "            ent1 = modifier +\" \"+ prefix + \" \"+ tok.text\n",
        "            prefix = \"\"\n",
        "            modifier = \"\"\n",
        "            prv_tok_dep = \"\"\n",
        "            prv_tok_text = \"\"      \n",
        "\n",
        "          ## chunk 4\n",
        "          if tok.dep_.find(\"obj\") == True:\n",
        "            ent2 = modifier +\" \"+ prefix +\" \"+ tok.text\n",
        "            \n",
        "          ## chunk 5  \n",
        "          # update variables\n",
        "          prv_tok_dep = tok.dep_\n",
        "          prv_tok_text = tok.text\n",
        "      #############################################################\n",
        "\n",
        "      return [ent1.strip(), ent2.strip()]\n",
        "\n",
        "    entity_pairs = []\n",
        "\n",
        "    for i in tqdm(country_data[\"notes\"]):\n",
        "      entity_pairs.append(get_entities(i))\n",
        "\n",
        "    \n",
        "    def get_relation(sent):\n",
        "      \n",
        "      doc = nlp(sent)\n",
        "\n",
        "      # Matcher class object \n",
        "      matcher = Matcher(nlp.vocab)\n",
        "\n",
        "      #define the pattern \n",
        "      pattern = [{'DEP':'ROOT'}, \n",
        "                {'DEP':'prep','OP':\"?\"},\n",
        "                {'DEP':'agent','OP':\"?\"},  \n",
        "                {'POS':'ADJ','OP':\"?\"}] \n",
        "\n",
        "      matcher.add(\"matching_1\", None, pattern) \n",
        "\n",
        "      matches = matcher(doc)\n",
        "      k = len(matches) - 1\n",
        "\n",
        "      span = doc[matches[k][1]:matches[k][2]] \n",
        "\n",
        "      return(span.text)\n",
        "\n",
        "\n",
        "    relations = [get_relation(i) for i in tqdm(country_data[\"notes\"])]\n",
        "\n",
        "\n",
        "    # extract subject\n",
        "    source = [i[0] for i in entity_pairs]\n",
        "\n",
        "    # extract object\n",
        "    target = [i[1] for i in entity_pairs]\n",
        "\n",
        "    ## Create entities and relation data frame\n",
        "    kg_df = pd.DataFrame({'source':source, 'target':target, 'edge':relations})\n",
        "\n",
        "    st.dataframe(kg_df)\n",
        "\n",
        "    ## List top 50 relations\n",
        "    st.write('The top 50 relations discovered are:')\n",
        "\n",
        "    st.write(pd.Series(relations).value_counts()[:50])\n",
        "\n",
        "    st.success('Network analysis completed.')\n",
        "\n",
        "    st.subheader(\"Relation Knowledge Graph\")\n",
        "\n",
        "    st.write('Select relation to be displayed on the knowledge graph')\n",
        "\n",
        "    select_relations = pd.Series(relations).value_counts()[:50].index.tolist()\n",
        "\n",
        "    select_relations = pd.DataFrame(select_relations,columns=['relations'])\n",
        "\n",
        "    select_relations.to_csv('select_relations.csv',index=False)\n",
        "    #st.dataframe(select_relations)\n",
        "\n",
        "    kg_df.to_csv('kg_df.csv',index= False)\n",
        "select_relations = pd.read_csv('select_relations.csv')\n",
        "selected_relation = st.selectbox('Select relation to be displayed on knowledge graph',select_relations['relations'])\n",
        "\n",
        "if st.button('Generate Knowledge Graph'):\n",
        "  with st.spinner(\"Generating Knowledge Graph\"):\n",
        "    \n",
        "    kg_df = pd.read_csv('kg_df.csv')\n",
        "    #select_relations = pd.read_csv('select_relations.csv')\n",
        "\n",
        "\n",
        "    G = nx.from_pandas_edgelist(kg_df[kg_df['edge']==selected_relation], \"source\", \"target\", \n",
        "                              edge_attr=True,create_using=nx.MultiDiGraph())\n",
        "\n",
        "    plt.figure(figsize=(12,12))\n",
        "    pos = nx.spring_layout(G, k = 0.5) # k regulates the distance between nodes\n",
        "    ax = nx.draw(G, with_labels=True, node_color='skyblue', node_size=1500, edge_cmap=plt.cm.Blues, pos = pos)\n",
        "      \n",
        "    plt.savefig(\"graph.png\")\n",
        "    st.image('graph.png')\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2 Run Knowledge Graph Application"
      ],
      "metadata": {
        "id": "hSjmsjXEatuQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code snippet generates a URL for the application."
      ],
      "metadata": {
        "id": "CrsrDH_2bNOC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COyeRFfRuUwQ",
        "outputId": "80c62c87-38c5-442e-fd02-e467fb68a9ed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-04-22 02:50:16.322 INFO    numexpr.utils: NumExpr defaulting to 2 threads.\n",
            "/usr/local/lib/python3.7/dist-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.26.9) or chardet (3.0.4) doesn't match a supported version!\n",
            "  RequestsDependencyWarning)\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.2:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://34.81.168.41:8501\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 3.778s\n",
            "your url is: https://warm-cheetah-68.loca.lt\n",
            "tcmalloc: large alloc 1645092864 bytes == 0x55851b7a4000 @  0x7f1e5910c2a4 0x558493786424 0x5584936e84e8 0x558493647184 0x558493607902 0x55849367ac4d 0x558493547d14 0x558493677ff1 0x558493675cdd 0x55849360888a 0x5584936768f6 0x558493675cdd 0x55849360888a 0x5584936768f6 0x558493675a2e 0x558493675723 0x558493673acb 0x558493606ff9 0x558493606ef0 0x55849367a9a3 0x5584936087aa 0x558493676b4f 0x558493608ce9 0x558493609341 0x558493677ff1 0x5584936087aa 0x558493676b4f 0x5584936087aa 0x558493676b4f 0x558493608ce9 0x558493609341\n",
            "100% 1530/1530 [00:22<00:00, 67.96it/s]\n",
            "100% 1530/1530 [00:21<00:00, 72.45it/s]\n",
            "/usr/local/lib/python3.7/dist-packages/networkx/drawing/nx_pylab.py:579: MatplotlibDeprecationWarning: \n",
            "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
            "  if not cb.iterable(width):\n",
            "/usr/local/lib/python3.7/dist-packages/networkx/drawing/nx_pylab.py:676: MatplotlibDeprecationWarning: \n",
            "The iterable function was deprecated in Matplotlib 3.1 and will be removed in 3.3. Use np.iterable instead.\n",
            "  if cb.iterable(node_size):  # many node sizes\n",
            "100% 1530/1530 [00:22<00:00, 68.51it/s]\n",
            "100% 1530/1530 [00:20<00:00, 73.46it/s]\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!streamlit run app2.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hYx8aue4JbSW"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrYaae0AJarJ"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FlRZ18DJJajX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sh-VBLapJozK"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iB5cWVemJovU"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-nE-jJeJorI"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WFtQfiU8Jomz"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OILCpfjxJojB"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fxGVi6doJoc3"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KoiUUv6OJaZl"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzkrnYhRuBv9"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Module 3 Twist Streamlit EDA & KG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}